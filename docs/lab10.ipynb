{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: Grid Localization using Bayes Filter (Virtual Robot)\n",
    "\n",
    "### <span style=\"color:rgb(0,150,0)\">It is recommended that you close any heavy-duty applications running on your system while working on this lab.</span>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Classes\n",
    "There are five major classes (Commander, VirtualRobot, Mapper, BaseLocalization and Trajectory) that provide you with the necessary functions and variables for working your way through the lab. \n",
    "In this notebook, we discuss only the relevant functions and variables that are of use for this lab. \n",
    "You may refer to the python file for an understanding of how the various functions work, however, this is not entirely necessary as the Jupyter notebook should provide you with all the necessary information.\n",
    "<hr>\n",
    "\n",
    "# Configuration \n",
    "The configuration files are stored under the **config** directory. The **simulator** parameters are listed in [world.yaml](../config/world.yaml). Here, you can define the world, the robot specifications, mapping and localization parameters. Open the file to find more information on each of the parameters. \n",
    "\n",
    "The plotter configuration is defined in [plotter.yaml](../config/plotter.yaml). You can stick to the default values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Commander\n",
    "The **Commander** class (defined in *commander.py*) allows you to interact with the simulator and the plotter. <br>\n",
    "__NOTE__: The units of measurement are meters and radians.\n",
    "\n",
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th style=\"text-align: left; font-size: medium\">Member Functions</th>\n",
    "        <th style=\"text-align: left; font-size: medium\">Description</th style=\"text-align: left\">\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"font-family:monospace\">Utility Functions</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">sim_is_running()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Get the run status of the simulator.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">plotter_is_running()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Get the run status of the plotter.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"font-family:monospace\">Plotter Functions</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">plot_odom(x,y)</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Plot a point (x,y) in the plotter in red. Units are $(meters, meters)$.</span></th style=\"text-align: left\">\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">plot_gt(x,y)</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Plot a point (x,y) in the plotter in green. Units are $(meters, meters)$.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">plot_bel(x,y)</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Plot a point (x,y) in the plotter in blue. Units are $(meters, meters)$.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">plot_map()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Plot the map based on the map lines in <em>world.yaml</em>.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">reset_plotter()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Reset the plots in the plotter.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"font-family:monospace\">Simulator Functions</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">set_vel(linear_vel, angular_vel)</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Set the linear velocity $(m/s)$ and angular velocity $(rad/s)$ of the virtual robot.</span></th style=\"text-align: left\">\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">get_pose()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Get the odometry and ground truth poses of the virtual robot as two numpy arrays. The units of each pose are $(meters, meters, radians)$</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">get_sensor()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Get the ToF sensor data (in $meters$) of the virtual robot as a numpy column array.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">reset_sim()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Reset the virtual robot to its initial pose.</span></th>\n",
    "    </tr>    \n",
    "   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# VirtualRobot\n",
    "The class (defined in [robot.py](../robot.py)) provides member functions required to interact with the virtual robot in the simulator. \n",
    "It acts as a wrapper class that uses the Commander object.<br>\n",
    "You will utilize a similar wrapper class for the real robot.<br>\n",
    "\n",
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">set_vel(linear_vel, angular_vel)</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Set the linear velocity $(m/s)$ and angular velocity $(rad/s)$ of the virtual robot.</span></th style=\"text-align: left\">\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">get_pose()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Get the odometry and ground truth poses of the virtual robot as two numpy arrays such that each pose has the units</span> <span style=\"color:rgb(180,20,20); font-weight: bold\">$(meters, meters, degrees)$.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">get_sensor()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Get the ToF sensor data (in $meters$) of the virtual robot as a numpy column array.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">perform_observation_loop()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Perform the observation loop behavior, where the robot does a 360 degree turn in place while collecting equidistant (in the angular space) sensor data, starting with the first sensor reading taken at the robot's current heading. The number of sensor readings depends on the value of <em>observations_count</em> defined in <a href=\"../config/world.yaml\">world.yaml</a>. It returns two column numpy arrays consisting of the ranges and bearings of the sensor readings. Units are $meters$ and $degrees$, respectively.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">reset_sim()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Reset the virtual robot to its initial pose.</span></th>\n",
    "    </tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<ins>NOTE</ins>**: If you use **cmdr.get_pose()**, the pose information units are in $(meters, meters, radians)$. We need pose information in $(meters, meters, degrees)$ for discrete localization, and the VirtualRobot class helps satisfy this requirement. <br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "# Mapper class\n",
    "- The class (defined in [localization.py](../localization.py)) provides member functions to handle various operations related to the grid map.\n",
    "- The discrete grid map spans a world of:\n",
    "    - $[-1.6764, +1.9812)~meters$ or $[-5.5, 6.5)~feet$ in the x-axis, \n",
    "    - $[-1.3716, +1.3716) meters$ or $[-5.5, +4.5) feet$ in the y-axis,and \n",
    "    - $[-180, 180)~degrees$ in the $\\theta$-axis.\n",
    "- The dimensions of a grid cell in the x, y and $\\theta$ axes are $0.3048~meters$, $0.3048~meters$ and $20~degrees$, respectively.\n",
    "- The grid has $12$, $9$ and $18$ cells along the three dimensions, with a total number of $1944$ cells.\n",
    "- The mapper class utilizes the line segments used to define the world, performs raytracing at the center of each discrete pose, and precaches the ground truth observations for later retrieval.\n",
    "\n",
    "Below is a summary of the necessary member functions and variables that will be required to complete this lab: <br>\n",
    "*('a' stands for 'angle')*\n",
    "\n",
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\">Member Functions</th>\n",
    "        <th style=\"text-align: left\">Description</th style=\"text-align: left\">\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">from_map(cx, cy, ca)</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Returns the continuous world coordinates <em>(x,y,a)</em> of the center of the grid cell index <em>(cx, cy, ca)</em></span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">to_map(x, y, a)</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Returns the grid map cell index <em>(cx, cy, ca)</em> of the continuous world coordinates <em>(x,y,a)</em>.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">normalize_angle(a)</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Normalizes the angle <em>a</em> to the interval [-180, 180).</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">get_views(cx, cy, ca)</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Returns a 1D array (with a size of OBS_PER_CELL) of the precached true measurements (views) at a given grid cell index <em>(cx, cy, ca)</em>. The true measurements are calculated offline by performing ray cast operations from the center of each cell in the map.</span></th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"font-family:monospace\">Member Variables</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(100,191,100);font-family:monospace\">MAX_CELLS_X, MAX_CELLS_Y, MAX_CELLS_A</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\"> Maximum number of grid cells in the X, Y and A directions, respectively.</em></span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(100,191,100);font-family:monospace\">OBS_PER_CELL</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Number of observations per cell. The number of observations made depends on \"observations_count\" defined in <a href=\"../config/world.yaml\">world.yaml</a>. The default value is 18.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(100,191,100);font-family:monospace\">obs_views</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">A 4D Numpy array where the first three dimensions represent the cell index <em>(cx, cy, ca)</em> and the fourth dimension represents the precached true measurements (views). Hence the size of the Numpy array is (12,9,18,18). You may think of it as a 3D array representing the grid where each cell stores 18 precached true measurements calculated using ray casting from the center of that cell.</span></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# BaseLocalization class\n",
    "The class (defined in [localization.py](../localization.py)) provides member functions and member variables required for Grid Localization. <br>\n",
    "Below is a summary of the necessary member functions and variables that will be required to complete this lab:\n",
    "\n",
    "\n",
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\">Member Functions</th>\n",
    "        <th style=\"text-align: left\">Description</th style=\"text-align: left\">\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">init_grid_beliefs()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Initialize the member variable <b>bel</b> with a uniform distribution.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">gaussian(x, mu, sigma)</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Returns the relative likelihood of <em>x</em> in a Normal Distribution with mean <em>mu</em> and standard deviation <em>sigma</em>.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">get_observation_data()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">Perform the observation loop behavior, where the robot does a 360 degree turn in place while collecting equidistant (in the angular space) sensor data, starting with the first sensor reading taken at the robot's current heading. The number of observations made depends on OBS_PER_CELL defined in the Mapper class. The range measurements are stored in the member variable <em>obs_range_data</em> of class <em>BaseLocalization</em>.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">print_prediction_stats(plot_data)</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">A helper function that displays statistics after your prediction step and plots the ground truth position (green), odometry position (red) and visualizes the prior belief (grayscale grid) if <em>plot_data</em> is True.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">print_update_stats(plot_data)</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">A helper function that displays statistics after your update step and plots the belief position (blue) if <em>plot_data</em> is True.</span></th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"font-family:monospace\">Member Variables</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(100,191,100);font-family:monospace\">obs_range_data</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\"> A column numpy array containing range measurements made by a robot after completing an observation rotation behavior i.e after calling the function <em>get_observation_data()</em>.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(100,191,100);font-family:monospace\">bel_bar</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">A 3D numpy array that is used to represent the prior belief of the robot i.e after the most recent prediction step.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(100,191,100);font-family:monospace\">bel</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">A 3D numpy array that is used to represent the belief of the robot i.e after the most recent update step. It is initialized with a uniform distribution at t=0.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(100,191,100);font-family:monospace\">sensor_sigma</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">The noise parameter (standard deviation of the Gaussian function) for your sensor model (defined in <a href=\"../config/world.yaml\">world.yaml</a>). </span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(100,191,100);font-family:monospace\">odom_rot_sigma</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">The noise parameter (standard deviation of the Gaussian function) for rotation in your odometry motion model (defined in <a href=\"../config/world.yaml\">world.yaml</a>).</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(100,191,100);font-family:monospace\">odom_trans_sigma</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">The noise parameter (standard deviation of the Gaussian function) for translation in your odometry motion model (defined in <a href=\"../config/world.yaml\">world.yaml</a>).</span></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<ins>NOTE</ins>**: The noise parameters are dependent on the robot motion model, sensor model and grid discretization. The values are thus tuned to work for the lab setting. **Do not change the noise parameters.**\n",
    "\n",
    "\n",
    "**<ins>NOTE</ins>**: The function **print_update_stats()** visualizes a 3D (grid) Belief in a 2D (grid) space in the plotter by marginalizing over  $\\theta$ i.e $\\overline{bel}(x,y) = \\sum_{\\theta} \\overline{bel}(x,y,\\theta)$. <br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "# Trajectory\n",
    "The trajectory class (defined in [Traj.py](../Traj.py)) encodes a pre-planned collision free trajectory to be executed by your robot. <br>\n",
    "\n",
    "**<ins>NOTE</ins>**:\n",
    "- <span style=\"color:rgb(100,191,100)\">You may have to change the trajectory motion commands  (check <b>init_motion_commands()</b> in <a href=\"../Traj.py\">Traj.py</a>) if the robot collides with its environment or if you want to test localization for a different trajectory.</span>\n",
    "- <span style=\"color:rgb(100,191,100)\">Do not use the keyboard to move the robot while executing the pre-planned trajectory motion. </span>\n",
    "    \n",
    "<table align=\"left\">\n",
    "     <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"font-family:monospace\">Member Functions</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(201,152,4);font-family:monospace\">execute_time_step()</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\"> Executes the motion at time step <em>t</em> and returns <em>prev_odom, current_odom, prev_gt, current_gt</em>, where <em>prev_odom</em> is the odometry pose before executing the motion, <em>current_odom</em> is the odometry pose after executing the motion, <em>prev_gt</em> is the ground truth pose before executing the motion, and <em>current_gt</em> is the ground truth pose after executing the motion.</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"font-family:monospace\">Member Variables</span></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align: left\"><span style=\"color:rgb(100,191,100);font-family:monospace\">total_time_steps</span></th>\n",
    "        <th style=\"text-align: left\"><span style=\"font-weight: normal\">The total number of time steps in the trajectory.</span></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, calling the member function **execute_time_step(t)** repeatedly from **t=0** to **t=total_time_steps-1** will make the robot execute the entire collision-free, pre-planned trajectory.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import traceback\n",
    "from notebook_utils import *\n",
    "from Traj import *\n",
    "import asyncio\n",
    "\n",
    "# Setup Logger\n",
    "LOG = get_logger('demo_notebook.log')\n",
    "\n",
    "# Init GUI and Commander\n",
    "gui = GET_GUI()\n",
    "cmdr = gui.launcher.commander\n",
    "\n",
    "gui.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the simulator\n",
    "START_SIM()\n",
    "\n",
    "# Start the plotter\n",
    "START_PLOTTER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the simulator\n",
    "STOP_SIM()\n",
    "\n",
    "# Start the plotter\n",
    "STOP_PLOTTER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Robot to communicate with the virtual robot and plotter\n",
    "robot = VirtualRobot(cmdr)\n",
    "\n",
    "# Initialize mapper\n",
    "# Requires a VirtualRobot object as a parameter\n",
    "mapper = Mapper(robot)\n",
    "\n",
    "# Initialize your BaseLocalization object\n",
    "# Requires a VirtualRobot object and a Mapper object as parameters\n",
    "loc = BaseLocalization(robot, mapper)\n",
    "\n",
    "## Plot Map\n",
    "cmdr.plot_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Trajectory\n",
    "- The below cell showcases how to use the **Trajectory** class to go through a pre-planned motion trajectory. \n",
    "- The cell does not run any sort of probabilistic estimation. It simply executes the motion in each time step in a successive manner. \n",
    "- Run the cell once and monitor how the robot executes the entire, collision-free trajectory. \n",
    "> You may have to change the trajectory motion commands (check <b>init_motion_commands()</b> in <a href=\"../Traj.py\">Traj.py</a>) if the robot collides with its environment or if you want to test localization for a different trajectory.\n",
    "\n",
    "**Make sure you go through the motion in a sequenctial manner in order to execute a collision free trajectory.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trajectory object\n",
    "traj = Trajectory(loc)\n",
    "\n",
    "# Run through each motion step and plot the current odom and gt poses\n",
    "for t in range(0, traj.total_time_steps):\n",
    "    # Execute control at t=0\n",
    "    prev_odom, current_odom, prev_gt, current_gt = traj.execute_time_step(t)\n",
    "    \n",
    "    # Plot Odom and GT\n",
    "    cmdr.plot_odom(current_odom[0], current_odom[1])\n",
    "    cmdr.plot_gt(current_gt[0], current_gt[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Observation Data\n",
    "\n",
    "- The robot is designed to executes a 360 rotation behavior where it rotates in place to collect 18 (=*OBS_PER_CELL*) range measurements at equidistant angular intervals over the 360 degree space. This mimics a 360 degree laser scanner, with the first reading at the robot's current heading. The range measurements are stored in the member variable **obs_range_data** of class **BaseLocalization**.\n",
    "\n",
    "- The cell below runs the **get_observation_data()** to execute this pre-planned behavior once at its current pose. Notice the virtual robot rotating in-place in the simulator. Make note of the shape of the numpy array containing the range data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Observation Data by executing a 360 degree rotation motion\n",
    "loc.get_observation_data()\n",
    "\n",
    "# Print the latest observation data stored in the member variable obs_range_data\n",
    "print(loc.obs_range_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above behavior will be repeated after each time step in the pre-planned trajectory to get the required observation data ($z_{t}$) at each time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Localization\n",
    "\n",
    "- The cell below contains skeleton code for various functions required to perform grid localization using Bayes Filter.\n",
    "- Write necessary code for each function definition.\n",
    "- You may add more functions or edit a function's definition to have a different input (arguments) and/or output (return values). For example, you may use numpy matrix operations to calculate the sensor model directly in the **update_step()** function and thus skip the *sensor_model()* function.<br>\n",
    "\n",
    "**<ins>NOTE</ins>**: \n",
    "- <span style=\"color:rgb(0,150,0)\">Make sure you refer to the section \"Implementation Tips\" in the lab documentation.</span> <br>\n",
    "- <span style=\"color:rgb(0,150,0)\">If you make changes to any of the functions below, make sure to re-run the below cell.</span> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the docstring, \"pose\" refers to a numpy array with elements (x,y,yaw) in (meters, meters, degrees)\n",
    "\n",
    "def compute_control(cur_pose, prev_pose):\n",
    "    \"\"\" Given the current and previous odometry poses, this function extracts\n",
    "    the control information based on the odometry motion model.\n",
    "\n",
    "    Args:\n",
    "        cur_pose  ([Pose]): Current Pose\n",
    "        prev_pose ([Pose]): Previous Pose \n",
    "\n",
    "    Returns:\n",
    "        [delta_rot_1]: Rotation 1  (degrees)\n",
    "        [delta_trans]: Translation (meters)\n",
    "        [delta_rot_2]: Rotation 2  (degrees)\n",
    "    \"\"\"\n",
    "\n",
    "    return delta_rot_1, delta_trans, delta_rot_2\n",
    "\n",
    "def odom_motion_model(cur_pose, prev_pose, u):\n",
    "    \"\"\" Odometry Motion Model\n",
    "\n",
    "    Args:\n",
    "        cur_pose  ([Pose]): Current Pose\n",
    "        prev_pose ([Pose]): Previous Pose\n",
    "        (rot1, trans, rot2) (float, float, float): A tuple with control data in the format \n",
    "                                                   format (rot1, trans, rot2) with units (degrees, meters, degrees)\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        prob [float]: Probability p(x'|x, u)\n",
    "    \"\"\"\n",
    "\n",
    "    return prob\n",
    "\n",
    "def prediction_step(cur_odom, prev_odom):\n",
    "    \"\"\" Prediction step of the Bayes Filter.\n",
    "    Update the probabilities in loc.bel_bar based on loc.bel from the previous time step and the odometry motion model.\n",
    "\n",
    "    Args:\n",
    "        cur_odom  ([Pose]): Current Pose\n",
    "        prev_odom ([Pose]): Previous Pose\n",
    "    \"\"\"\n",
    "\n",
    "def sensor_model(obs):\n",
    "    \"\"\" This is the equivalent of p(z|x).\n",
    "\n",
    "\n",
    "    Args:\n",
    "        obs ([ndarray]): A 1D array consisting of the true observations for a specific robot pose in the map \n",
    "\n",
    "    Returns:\n",
    "        [ndarray]: Returns a 1D array of size 18 (=loc.OBS_PER_CELL) with the likelihoods of each individual sensor measurement\n",
    "    \"\"\"\n",
    "\n",
    "    return prob_array\n",
    "\n",
    "def update_step():\n",
    "    \"\"\" Update step of the Bayes Filter.\n",
    "    Update the probabilities in loc.bel based on loc.bel_bar and the sensor model.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Bayes Filter\n",
    "The cells below utilizes the functions declared above to run each iteration of the Bayes filter algorithm to localize the robot in the grid. <br>\n",
    "\n",
    "In each iteration of the loop:\n",
    "- Execute robot motion (get $u_{t}$ as previous and current odom) \n",
    "- Perform prediction step (calculate $\\overline{bel}$)\n",
    "- Print information regarding Prediction step\n",
    "- Execute robot rotation behavior to get observation data (get $z_{t}$)\n",
    "- Perform update step (calculate $bel$)\n",
    "- Print information regarding update step\n",
    "\n",
    "\n",
    "**<ins>NOTE</ins>**: \n",
    "- During initial testing, you may want to limit the iteration to only the first time step (i.e t=0) instead of looping through the entire trajectory.\n",
    "- <span style=\"color:rgb(0,150,0)\">If you make changes to any of the functions above, make sure to re-run the above cells before executing the cell below.</span>\n",
    "- The functions *print_prediction_stats()* and *print_update_stats()* are helper functions defined in <a href=\"../localization.py\">localization.py</a> and may be changed to suit your needs.\n",
    "- <span style=\"color:rgb(0,150,0)\">Always run an initial update step before the first prediction step.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cell below contains code to initialize a uniform probability distribution and perform the update step of the Bayes Filter to localize the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Robot and Plots\n",
    "robot.reset()\n",
    "cmdr.reset_plotter()\n",
    "\n",
    "# Init Uniform Belief\n",
    "loc.init_grid_beliefs()\n",
    "\n",
    "# Get Observation Data by executing a 360 degree rotation motion\n",
    "loc.get_observation_data()\n",
    "\n",
    "# Run Update Step\n",
    "update_step()\n",
    "loc.print_update_stats(plot_data=True)\n",
    "\n",
    "# Plot Odom and GT\n",
    "current_odom, current_gt = robot.get_pose()\n",
    "cmdr.plot_gt(current_gt[0], current_gt[1])\n",
    "cmdr.plot_odom(current_odom[0], current_odom[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trajectory object\n",
    "traj = Trajectory(loc)\n",
    "\n",
    "# Run through each motion steps\n",
    "for t in range(0, traj.total_time_steps):\n",
    "    print(\"\\n\\n-----------------\", t, \"-----------------\")\n",
    "    \n",
    "    prev_odom, current_odom, prev_gt, current_gt = traj.execute_time_step(t)\n",
    "        \n",
    "    # Prediction Step\n",
    "    prediction_step(current_odom, prev_odom)\n",
    "    loc.print_prediction_stats(plot_data=True)\n",
    "    \n",
    "    # Get Observation Data by executing a 360 degree rotation motion\n",
    "    loc.get_observation_data()\n",
    "    \n",
    "    # Update Step\n",
    "    update_step()\n",
    "    loc.print_update_stats(plot_data=True)\n",
    "\n",
    "# Uncomment the below line to wait for keyboard input between each iteration.\n",
    "#   input(\"Press Enter to Continue\")\n",
    "        \n",
    "    print(\"-------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
